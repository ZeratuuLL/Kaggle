{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from catboost import CatBoostClassifier\n",
    "from transforms import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('first_round_training_data.csv')\n",
    "testing = pd.read_csv('first_round_testing_data.csv')\n",
    "features = [\"Parameter5\",\"Parameter6\",\"Parameter7\",\"Parameter8\",\"Parameter9\",\"Parameter10\"]\n",
    "\n",
    "training[features] = np.log(training[features].values)/np.log(10)\n",
    "testing[features] = np.log(testing[features].values)/np.log(10)\n",
    "\n",
    "code = {'Pass':1, 'Good':2, 'Excellent':3, 'Fail':0}\n",
    "training['new_Quality'] = training['Quality_label'].apply(lambda x : code[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this is original data\n",
    "new_features = ['Parameter'+str(i) for i in [5, 7, 8, 9, 10]]\n",
    "train_all, test_all = training.copy(), testing.copy()\n",
    "new_features = new_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# this is log data and PCA\\nnew_features = ['Parameter'+str(i) for i in range(5, 11)]\\ntrain_all, test_all = training.copy(), testing.copy()\\nnew_values = pca.fit_transform(pd.concat([train_all[new_features], test_all[new_features]]))\\ntrain_all[new_features] = new_values[:6000, :].copy()\\ntest_all[new_features] = new_values[6000:, :].copy()\\nnew_features = new_features[:6]\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# this is log data and PCA\n",
    "new_features = ['Parameter'+str(i) for i in range(5, 11)]\n",
    "train_all, test_all = training.copy(), testing.copy()\n",
    "new_values = pca.fit_transform(pd.concat([train_all[new_features], test_all[new_features]]))\n",
    "train_all[new_features] = new_values[:6000, :].copy()\n",
    "test_all[new_features] = new_values[6000:, :].copy()\n",
    "new_features = new_features[:6]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# this is Target Mean Encoding\\ntrain_all, test_all, new_features = get_all_encoding(training, testing, features)\\nnew_values = pca.fit_transform(pd.concat([train_all[new_features], test_all[new_features]]))\\ntrain_all[new_features] = new_values[:6000, :].copy()\\ntest_all[new_features] = new_values[6000:, :].copy()\\nnew_features = new_features[:15]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# this is Target Mean Encoding\n",
    "train_all, test_all, new_features = get_all_encoding(training, testing, features)\n",
    "new_values = pca.fit_transform(pd.concat([train_all[new_features], test_all[new_features]]))\n",
    "train_all[new_features] = new_values[:6000, :].copy()\n",
    "test_all[new_features] = new_values[6000:, :].copy()\n",
    "new_features = new_features[:15]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# this is Weight of Evidence Encoding\\ntrain_all, test_all, new_features = get_all_WoE(training, testing, features)\\nnew_values = pca.fit_transform(pd.concat([train_all[new_features], test_all[new_features]]))\\ntrain_all[new_features] = new_values[:6000, :].copy()\\ntest_all[new_features] = new_values[6000:, :].copy()\\nnew_features = new_features[:17]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# this is Weight of Evidence Encoding\n",
    "train_all, test_all, new_features = get_all_WoE(training, testing, features)\n",
    "new_values = pca.fit_transform(pd.concat([train_all[new_features], test_all[new_features]]))\n",
    "train_all[new_features] = new_values[:6000, :].copy()\n",
    "test_all[new_features] = new_values[6000:, :].copy()\n",
    "new_features = new_features[:17]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 10\n",
    "learning_rate = 0.1\n",
    "l2_leaf_reg = 10\n",
    "min_data_in_leaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations = 3000, \n",
    "                           depth = depth, \n",
    "                           learning_rate = learning_rate, \n",
    "                           silent = True, \n",
    "                           loss_function = 'MultiClass', \n",
    "                           l2_leaf_reg = l2_leaf_reg,\n",
    "                           od_type = 'Iter',\n",
    "                           od_wait = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N, shuffle=True)\n",
    "indices = []\n",
    "for train_index, test_index in skf.split(training[features], training[['new_Quality']]):\n",
    "    indices.append([train_index, test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3390799\ttest: 1.3408722\tbest: 1.3408722 (0)\ttotal: 153ms\tremaining: 7m 39s\n",
      "250:\tlearn: 1.0065242\ttest: 1.0842564\tbest: 1.0842564 (250)\ttotal: 17.5s\tremaining: 3m 11s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.083715983\n",
      "bestIteration = 286\n",
      "\n",
      "Shrink model to first 287 iterations.\n",
      "1 out of 5 finished.\n",
      "0:\tlearn: 1.3414652\ttest: 1.3421876\tbest: 1.3421876 (0)\ttotal: 86.6ms\tremaining: 4m 19s\n",
      "250:\tlearn: 1.0098129\ttest: 1.0702740\tbest: 1.0701862 (248)\ttotal: 17.9s\tremaining: 3m 15s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.069924018\n",
      "bestIteration = 350\n",
      "\n",
      "Shrink model to first 351 iterations.\n",
      "2 out of 5 finished.\n",
      "0:\tlearn: 1.3420935\ttest: 1.3426830\tbest: 1.3426830 (0)\ttotal: 86.4ms\tremaining: 4m 19s\n",
      "250:\tlearn: 1.0049409\ttest: 1.0804810\tbest: 1.0803066 (248)\ttotal: 19.2s\tremaining: 3m 30s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.079486886\n",
      "bestIteration = 287\n",
      "\n",
      "Shrink model to first 288 iterations.\n",
      "3 out of 5 finished.\n",
      "0:\tlearn: 1.3437499\ttest: 1.3460008\tbest: 1.3460008 (0)\ttotal: 84.6ms\tremaining: 4m 13s\n",
      "250:\tlearn: 1.0059660\ttest: 1.0813888\tbest: 1.0813121 (165)\ttotal: 19s\tremaining: 3m 28s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.080859087\n",
      "bestIteration = 270\n",
      "\n",
      "Shrink model to first 271 iterations.\n",
      "4 out of 5 finished.\n",
      "0:\tlearn: 1.3444331\ttest: 1.3457590\tbest: 1.3457590 (0)\ttotal: 89.5ms\tremaining: 4m 28s\n",
      "250:\tlearn: 1.0026485\ttest: 1.0871724\tbest: 1.0869066 (209)\ttotal: 19.4s\tremaining: 3m 32s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.086368956\n",
      "bestIteration = 275\n",
      "\n",
      "Shrink model to first 276 iterations.\n",
      "5 out of 5 finished.\n"
     ]
    }
   ],
   "source": [
    "prob_predict = np.zeros((6000, 4))\n",
    "for j in range(N):\n",
    "    train_index = indices[j][0]\n",
    "    test_index = indices[j][1]\n",
    "    X_train = train_all.loc[train_index, new_features]\n",
    "    y_train = train_all.loc[train_index, ['new_Quality']]\n",
    "    X_test = train_all.loc[test_index, new_features]\n",
    "    y_test = train_all.loc[test_index, ['new_Quality']]\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=250)\n",
    "    prob_predict += model.predict_proba(test_all[new_features])\n",
    "    print('{} out of {} finished.'.format(j+1, N))\n",
    "prob_predict /= N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(values):\n",
    "    values = values/0.02\n",
    "    upper = np.ceil(values)\n",
    "    lower = np.floor(values)\n",
    "    for i in range(values.shape[0]):\n",
    "        smallest_error = 10000\n",
    "        for a in [upper[i, 0], lower[i, 0]]:\n",
    "            for b in [upper[i, 1], lower[i, 1]]:\n",
    "                for c in [upper[i, 2], lower[i, 2]]:\n",
    "                    for d in [upper[i, 3], lower[i, 3]]:\n",
    "                        if a+b+c+d == 50:\n",
    "                            new_value = np.array([a, b, c, d])\n",
    "                            new_error = np.mean(np.abs(new_value - values[i, :]))\n",
    "                            if new_error < smallest_error:\n",
    "                                smallest_error = new_error\n",
    "                                best_option = new_value\n",
    "        values[i, :] = best_option.copy()\n",
    "    return values*0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(prob_predict, submit=False, name='submission'):\n",
    "    testing['Fail ratio'] = 0\n",
    "    testing['Pass ratio'] = 0\n",
    "    testing['Good ratio'] = 0\n",
    "    testing['Excellent ratio'] = 0\n",
    "    testing[['Fail ratio', 'Pass ratio', 'Good ratio', 'Excellent ratio']] = prob_predict\n",
    "    submission = testing.groupby(['Group'], as_index=False).mean()\n",
    "    submission = submission[['Group', 'Excellent ratio', 'Good ratio', 'Pass ratio', 'Fail ratio']]\n",
    "    if submit:\n",
    "        submission.to_csv('{}.csv'.format(name), index=False)\n",
    "    matrix1 = submission[['Excellent ratio', 'Good ratio', 'Pass ratio', 'Fail ratio']].values.copy()\n",
    "    matrix2 = normalize(matrix1)\n",
    "    submission[['Excellent ratio', 'Good ratio', 'Pass ratio', 'Fail ratio']] = matrix2.copy()\n",
    "    if submit:\n",
    "        submission.to_csv('{}_rounded.csv'.format(name), index=False)\n",
    "    return matrix1, matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1, matrix2 = get_prediction(prob_predict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
