{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR = 0.05\n",
    "DEPTH = 4\n",
    "EARLY_STOP = 10\n",
    "MAX_ITERATION = 2900\n",
    "MIN_ITERATION = 80\n",
    "LEARNING_RATE = 0.01\n",
    "N = 10\n",
    "\n",
    "def check(data, col_name, n):\n",
    "    #data = data.loc[np.abs(data['train_neg_log_loss_mean'] - data['validate_neg_log_loss'])<ERROR, :]\n",
    "    #data = data.loc[data['Iterations']>EARLY_STOP, :]\n",
    "    data = data.loc[np.logical_or(data['depth']>=DEPTH, data['learning_rate']>=LEARNING_RATE), :]\n",
    "    data = data.loc[data['best_iterations_mean']<=MAX_ITERATION, :]\n",
    "    data = data.loc[data['best_iterations_mean']>=MIN_ITERATION, :]\n",
    "    values = data[col_name].values\n",
    "    ids = np.argsort(-values)[:n]\n",
    "    return data.iloc[ids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value(data, col_name, target_value, n):\n",
    "    values = data[col_name].values\n",
    "    values = np.abs(values - target_value)\n",
    "    ids = np.argsort(values)[:n]\n",
    "    return data.iloc[ids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>min_sample_in_leaf</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.011416</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.575583</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>-1.085680</td>\n",
       "      <td>0.535833</td>\n",
       "      <td>0.698528</td>\n",
       "      <td>0.699526</td>\n",
       "      <td>0.008793</td>\n",
       "      <td>0.039571</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>467.8</td>\n",
       "      <td>87.378258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>-0.997582</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>0.579207</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>-1.084086</td>\n",
       "      <td>0.535667</td>\n",
       "      <td>0.698450</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>59.869859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>-1.002966</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.577374</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>-1.084913</td>\n",
       "      <td>0.535333</td>\n",
       "      <td>0.698352</td>\n",
       "      <td>0.699293</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20.0</td>\n",
       "      <td>700.4</td>\n",
       "      <td>106.183991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-1.004986</td>\n",
       "      <td>0.014416</td>\n",
       "      <td>0.575958</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>-1.084990</td>\n",
       "      <td>0.531667</td>\n",
       "      <td>0.698372</td>\n",
       "      <td>0.699269</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>345.6</td>\n",
       "      <td>97.448653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>-1.003113</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.576624</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>-1.084829</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.698374</td>\n",
       "      <td>0.699268</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10.0</td>\n",
       "      <td>494.2</td>\n",
       "      <td>71.362175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>-0.997448</td>\n",
       "      <td>0.007738</td>\n",
       "      <td>0.579250</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>-1.085155</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>0.698219</td>\n",
       "      <td>0.699186</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>0.039115</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20.0</td>\n",
       "      <td>486.8</td>\n",
       "      <td>64.328532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.020576</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.569792</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>-1.086587</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>0.698402</td>\n",
       "      <td>0.699185</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.038749</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>510.6</td>\n",
       "      <td>42.287587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.587458</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-1.085528</td>\n",
       "      <td>0.532833</td>\n",
       "      <td>0.698092</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.038131</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10.0</td>\n",
       "      <td>285.4</td>\n",
       "      <td>54.854717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>-0.979366</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>0.587584</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>-1.086900</td>\n",
       "      <td>0.529333</td>\n",
       "      <td>0.698080</td>\n",
       "      <td>0.699131</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150.6</td>\n",
       "      <td>32.536748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>-1.004253</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.577125</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>-1.085807</td>\n",
       "      <td>0.532167</td>\n",
       "      <td>0.698395</td>\n",
       "      <td>0.699124</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.038703</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>30.0</td>\n",
       "      <td>432.4</td>\n",
       "      <td>61.921240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "1                 -1.011416                0.006403             0.575583   \n",
       "17                -0.997582                0.009105             0.579207   \n",
       "22                -1.002966                0.006988             0.577374   \n",
       "18                -1.004986                0.014416             0.575958   \n",
       "21                -1.003113                0.006828             0.576624   \n",
       "38                -0.997448                0.007738             0.579250   \n",
       "2                 -1.020576                0.005800             0.569792   \n",
       "53                -0.983000                0.012958             0.587458   \n",
       "49                -0.979366                0.017657             0.587584   \n",
       "19                -1.004253                0.009161             0.577125   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "1             0.000870              -1.085680           0.535833   \n",
       "17            0.005480              -1.084086           0.535667   \n",
       "22            0.004168              -1.084913           0.535333   \n",
       "18            0.005167              -1.084990           0.531667   \n",
       "21            0.004253              -1.084829           0.536000   \n",
       "38            0.001374              -1.085155           0.534500   \n",
       "2             0.004227              -1.086587           0.534500   \n",
       "53            0.003638              -1.085528           0.532833   \n",
       "49            0.006827              -1.086900           0.529333   \n",
       "19            0.003156              -1.085807           0.532167   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "1                      0.698528                        0.699526   \n",
       "17                     0.698450                        0.699422   \n",
       "22                     0.698352                        0.699293   \n",
       "18                     0.698372                        0.699269   \n",
       "21                     0.698374                        0.699268   \n",
       "38                     0.698219                        0.699186   \n",
       "2                      0.698402                        0.699185   \n",
       "53                     0.698092                        0.699153   \n",
       "49                     0.698080                        0.699131   \n",
       "19                     0.698395                        0.699124   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  \\\n",
       "1                     0.008793                      0.039571   \n",
       "17                    0.008828                      0.038986   \n",
       "22                    0.008780                      0.038007   \n",
       "18                    0.008742                      0.038679   \n",
       "21                    0.008802                      0.038975   \n",
       "38                    0.008851                      0.039115   \n",
       "2                     0.008824                      0.038749   \n",
       "53                    0.008810                      0.038131   \n",
       "49                    0.008803                      0.037842   \n",
       "19                    0.008767                      0.038703   \n",
       "\n",
       "    min_sample_in_leaf  depth  learning_rate  l2_norm  best_iterations_mean  \\\n",
       "1                 10.0    4.0           0.10     10.0                 467.8   \n",
       "17                10.0    6.0           0.10     10.0                 272.0   \n",
       "22                10.0    6.0           0.05     20.0                 700.4   \n",
       "18                10.0    6.0           0.10     20.0                 345.6   \n",
       "21                10.0    6.0           0.05     10.0                 494.2   \n",
       "38                10.0    8.0           0.05     20.0                 486.8   \n",
       "2                 10.0    4.0           0.10     20.0                 510.6   \n",
       "53                10.0   10.0           0.05     10.0                 285.4   \n",
       "49                10.0   10.0           0.10     10.0                 150.6   \n",
       "19                10.0    6.0           0.10     30.0                 432.4   \n",
       "\n",
       "    best_iterations_std  \n",
       "1             87.378258  \n",
       "17            59.869859  \n",
       "22           106.183991  \n",
       "18            97.448653  \n",
       "21            71.362175  \n",
       "38            64.328532  \n",
       "2             42.287587  \n",
       "53            54.854717  \n",
       "49            32.536748  \n",
       "19            61.921240  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Original_5.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 4, lr 0.1, l2 10, rounded 0.68145800000\n",
    "# es 100, depth 6, lr 0.1, l2 10, rounded 0.68580544, 10 fold\n",
    "# es 100, depth 6, lr 0.1, l2 10, rounded 0.6825397\n",
    "# es 100, depth 6, lr 0.1, l2 10, rounded 0.6761006\n",
    "# es 100, depth 10, lr 0.1, l2 10, rounded 0.68145800000, 10 fold\n",
    "# es 100, depth 10, lr 0.1, l2 10, rounded 0.688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.994218</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.585166</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>-1.084980</td>\n",
       "      <td>0.531167</td>\n",
       "      <td>0.698365</td>\n",
       "      <td>0.699790</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>0.039247</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1567.6</td>\n",
       "      <td>116.801712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>-0.982281</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.590917</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>-1.084365</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>0.698387</td>\n",
       "      <td>0.699702</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.038919</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2162.2</td>\n",
       "      <td>211.684104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>-0.999233</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.581501</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>-1.085524</td>\n",
       "      <td>0.530833</td>\n",
       "      <td>0.698377</td>\n",
       "      <td>0.699694</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.039401</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>200.582153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>-0.991510</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.586625</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-1.084904</td>\n",
       "      <td>0.532833</td>\n",
       "      <td>0.698339</td>\n",
       "      <td>0.699675</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.038758</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2720.6</td>\n",
       "      <td>292.851908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>-0.993725</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>0.585792</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>-1.085835</td>\n",
       "      <td>0.530667</td>\n",
       "      <td>0.698374</td>\n",
       "      <td>0.699650</td>\n",
       "      <td>0.008867</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>544.4</td>\n",
       "      <td>75.838249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>-0.986985</td>\n",
       "      <td>0.012052</td>\n",
       "      <td>0.586916</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>-1.086259</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>0.698302</td>\n",
       "      <td>0.699615</td>\n",
       "      <td>0.008885</td>\n",
       "      <td>0.040228</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30.0</td>\n",
       "      <td>301.4</td>\n",
       "      <td>65.983634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>-0.980532</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.591416</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>-1.084480</td>\n",
       "      <td>0.533667</td>\n",
       "      <td>0.698402</td>\n",
       "      <td>0.699615</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>0.038776</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1107.8</td>\n",
       "      <td>39.209183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>-0.991048</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.585167</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>-1.084481</td>\n",
       "      <td>0.532333</td>\n",
       "      <td>0.698509</td>\n",
       "      <td>0.699612</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.039629</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>332.6</td>\n",
       "      <td>31.296006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>-0.988528</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.587749</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>-1.085099</td>\n",
       "      <td>0.532167</td>\n",
       "      <td>0.698318</td>\n",
       "      <td>0.699598</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.038874</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1432.4</td>\n",
       "      <td>170.433095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-0.984135</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.587709</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>-1.085847</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.698287</td>\n",
       "      <td>0.699594</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.040168</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>253.6</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "25                -0.994218                0.003586             0.585166   \n",
       "45                -0.982281                0.006405             0.590917   \n",
       "27                -0.999233                0.007356             0.581501   \n",
       "46                -0.991510                0.006106             0.586625   \n",
       "23                -0.993725                0.009959             0.585792   \n",
       "19                -0.986985                0.012052             0.586916   \n",
       "41                -0.980532                0.003048             0.591416   \n",
       "21                -0.991048                0.006421             0.585167   \n",
       "42                -0.988528                0.006073             0.587749   \n",
       "18                -0.984135                0.004032             0.587709   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "25            0.001946              -1.084980           0.531167   \n",
       "45            0.003750              -1.084365           0.534500   \n",
       "27            0.002588              -1.085524           0.530833   \n",
       "46            0.003638              -1.084904           0.532833   \n",
       "23            0.003464              -1.085835           0.530667   \n",
       "19            0.005930              -1.086259           0.533000   \n",
       "41            0.002037              -1.084480           0.533667   \n",
       "21            0.003401              -1.084481           0.532333   \n",
       "42            0.003994              -1.085099           0.532167   \n",
       "18            0.002149              -1.085847           0.532500   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "25                     0.698365                        0.699790   \n",
       "45                     0.698387                        0.699702   \n",
       "27                     0.698377                        0.699694   \n",
       "46                     0.698339                        0.699675   \n",
       "23                     0.698374                        0.699650   \n",
       "19                     0.698302                        0.699615   \n",
       "41                     0.698402                        0.699615   \n",
       "21                     0.698509                        0.699612   \n",
       "42                     0.698318                        0.699598   \n",
       "18                     0.698287                        0.699594   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  Iterations  \\\n",
       "25                    0.008859                      0.039247        10.0   \n",
       "45                    0.008886                      0.038919        10.0   \n",
       "27                    0.008881                      0.039401        10.0   \n",
       "46                    0.008906                      0.038758        10.0   \n",
       "23                    0.008867                      0.038975        10.0   \n",
       "19                    0.008885                      0.040228        10.0   \n",
       "41                    0.008894                      0.038776        10.0   \n",
       "21                    0.008848                      0.039629        10.0   \n",
       "42                    0.008897                      0.038874        10.0   \n",
       "18                    0.008871                      0.040168        10.0   \n",
       "\n",
       "    depth  learning_rate  l2_norm  best_iterations_mean  best_iterations_std  \n",
       "25    6.0          0.010     10.0                1567.6           116.801712  \n",
       "45    8.0          0.005     10.0                2162.2           211.684104  \n",
       "27    6.0          0.010     30.0                2457.0           200.582153  \n",
       "46    8.0          0.005     20.0                2720.6           292.851908  \n",
       "23    6.0          0.050     30.0                 544.4            75.838249  \n",
       "19    6.0          0.100     30.0                 301.4            65.983634  \n",
       "41    8.0          0.010     10.0                1107.8            39.209183  \n",
       "21    6.0          0.050     10.0                 332.6            31.296006  \n",
       "42    8.0          0.010     20.0                1432.4           170.433095  \n",
       "18    6.0          0.100     20.0                 253.6             7.200000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('PCA_Only_5.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 6, lr 0.1, l2 5, rounded 0.671875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.973460</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>0.599292</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>-1.083332</td>\n",
       "      <td>0.533833</td>\n",
       "      <td>0.698519</td>\n",
       "      <td>0.699762</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.037401</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1670.4</td>\n",
       "      <td>252.727996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>-0.979290</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>-1.084238</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.698424</td>\n",
       "      <td>0.699694</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>0.037516</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2627.6</td>\n",
       "      <td>326.335165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.988660</td>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.590670</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>-1.087299</td>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.698273</td>\n",
       "      <td>0.699688</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>0.036603</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>337.2</td>\n",
       "      <td>124.927819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-0.974867</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.598667</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>-1.083811</td>\n",
       "      <td>0.531833</td>\n",
       "      <td>0.698447</td>\n",
       "      <td>0.699684</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0.037662</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>402.459936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.985965</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.593584</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>-1.084136</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.698427</td>\n",
       "      <td>0.699671</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2835.8</td>\n",
       "      <td>191.855571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>-0.966003</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.602499</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>-1.083104</td>\n",
       "      <td>0.535167</td>\n",
       "      <td>0.698555</td>\n",
       "      <td>0.699655</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>0.037423</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>369.2</td>\n",
       "      <td>79.642702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>-0.953960</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.609792</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>-1.083145</td>\n",
       "      <td>0.533833</td>\n",
       "      <td>0.698372</td>\n",
       "      <td>0.699636</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.037141</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2322.4</td>\n",
       "      <td>303.223086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>-0.947335</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.612542</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>-1.083059</td>\n",
       "      <td>0.531333</td>\n",
       "      <td>0.698479</td>\n",
       "      <td>0.699609</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.037582</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>249.4</td>\n",
       "      <td>28.723510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>-0.968421</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>0.603416</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>-1.083893</td>\n",
       "      <td>0.534333</td>\n",
       "      <td>0.698292</td>\n",
       "      <td>0.699561</td>\n",
       "      <td>0.008720</td>\n",
       "      <td>0.037101</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2866.4</td>\n",
       "      <td>253.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>-0.957468</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.608334</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-1.083400</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>0.698323</td>\n",
       "      <td>0.699550</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>157.775790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "25                -0.973460                0.010231             0.599292   \n",
       "27                -0.979290                0.009004             0.595500   \n",
       "1                 -0.988660                0.027163             0.590670   \n",
       "26                -0.974867                0.013179             0.598667   \n",
       "29                -0.985965                0.004078             0.593584   \n",
       "21                -0.966003                0.015789             0.602499   \n",
       "45                -0.953960                0.011864             0.609792   \n",
       "37                -0.947335                0.011182             0.612542   \n",
       "46                -0.968421                0.006967             0.603416   \n",
       "41                -0.957468                0.012557             0.608334   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "25            0.006438              -1.083332           0.533833   \n",
       "27            0.004429              -1.084238           0.533333   \n",
       "1             0.013437              -1.087299           0.538333   \n",
       "26            0.007453              -1.083811           0.531833   \n",
       "29            0.004776              -1.084136           0.533333   \n",
       "21            0.007905              -1.083104           0.535167   \n",
       "45            0.003240              -1.083145           0.533833   \n",
       "37            0.004423              -1.083059           0.531333   \n",
       "46            0.001646              -1.083893           0.534333   \n",
       "41            0.005872              -1.083400           0.533000   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "25                     0.698519                        0.699762   \n",
       "27                     0.698424                        0.699694   \n",
       "1                      0.698273                        0.699688   \n",
       "26                     0.698447                        0.699684   \n",
       "29                     0.698427                        0.699671   \n",
       "21                     0.698555                        0.699655   \n",
       "45                     0.698372                        0.699636   \n",
       "37                     0.698479                        0.699609   \n",
       "46                     0.698292                        0.699561   \n",
       "41                     0.698323                        0.699550   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  Iterations  \\\n",
       "25                    0.008651                      0.037401        10.0   \n",
       "27                    0.008705                      0.037516        10.0   \n",
       "1                     0.008638                      0.036603        10.0   \n",
       "26                    0.008665                      0.037662        10.0   \n",
       "29                    0.008721                      0.037800        10.0   \n",
       "21                    0.008609                      0.037423        10.0   \n",
       "45                    0.008681                      0.037141        10.0   \n",
       "37                    0.008701                      0.037582        10.0   \n",
       "46                    0.008720                      0.037101        10.0   \n",
       "41                    0.008704                      0.036986        10.0   \n",
       "\n",
       "    depth  learning_rate  l2_norm  best_iterations_mean  best_iterations_std  \n",
       "25    6.0          0.010     10.0                1670.4           252.727996  \n",
       "27    6.0          0.010     30.0                2627.6           326.335165  \n",
       "1     4.0          0.100     10.0                 337.2           124.927819  \n",
       "26    6.0          0.010     20.0                2258.0           402.459936  \n",
       "29    6.0          0.005     10.0                2835.8           191.855571  \n",
       "21    6.0          0.050     10.0                 369.2            79.642702  \n",
       "45    8.0          0.005     10.0                2322.4           303.223086  \n",
       "37    8.0          0.050     10.0                 249.4            28.723510  \n",
       "46    8.0          0.005     20.0                2866.4           253.796454  \n",
       "41    8.0          0.010     10.0                1120.0           157.775790  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('PCA_Only_6.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 6, lr 0.05, l2 5, rounded 0.6771653\n",
    "# es 100, depth 6, lr 0.01, l2 10, rounded 0.67823344\n",
    "# es 100, depth 6, lr 0.01, l2 10, rounded 0.6771653, 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>-0.921704</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.636542</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>-1.079046</td>\n",
       "      <td>0.536333</td>\n",
       "      <td>0.698564</td>\n",
       "      <td>0.699907</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.041222</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>331.2</td>\n",
       "      <td>54.049607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>-0.971748</td>\n",
       "      <td>0.006853</td>\n",
       "      <td>0.602374</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>-1.078532</td>\n",
       "      <td>0.534667</td>\n",
       "      <td>0.698637</td>\n",
       "      <td>0.699896</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.041990</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2071.0</td>\n",
       "      <td>269.165377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.962020</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>0.608626</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>-1.077733</td>\n",
       "      <td>0.535833</td>\n",
       "      <td>0.698661</td>\n",
       "      <td>0.699891</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.041848</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1359.8</td>\n",
       "      <td>98.253550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-0.972980</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.601084</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>-1.078416</td>\n",
       "      <td>0.533833</td>\n",
       "      <td>0.698628</td>\n",
       "      <td>0.699880</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.042224</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1648.2</td>\n",
       "      <td>209.965140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>-0.963975</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>0.605918</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>-1.078497</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.698623</td>\n",
       "      <td>0.699867</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>364.8</td>\n",
       "      <td>35.050820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.967210</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>-1.077951</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>0.698652</td>\n",
       "      <td>0.699827</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2560.6</td>\n",
       "      <td>280.786467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>-0.969241</td>\n",
       "      <td>0.012705</td>\n",
       "      <td>0.603251</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>-1.078704</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.698608</td>\n",
       "      <td>0.699809</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.042516</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>428.6</td>\n",
       "      <td>61.467390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>-0.929359</td>\n",
       "      <td>0.016049</td>\n",
       "      <td>0.633125</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>-1.079837</td>\n",
       "      <td>0.534833</td>\n",
       "      <td>0.698511</td>\n",
       "      <td>0.699781</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.041595</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1035.4</td>\n",
       "      <td>164.077543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>-0.936107</td>\n",
       "      <td>0.010399</td>\n",
       "      <td>0.628708</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>-1.079403</td>\n",
       "      <td>0.533833</td>\n",
       "      <td>0.698540</td>\n",
       "      <td>0.699777</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>0.041706</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1936.2</td>\n",
       "      <td>224.867428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-1.007283</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.577750</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>-1.081280</td>\n",
       "      <td>0.535167</td>\n",
       "      <td>0.698291</td>\n",
       "      <td>0.699765</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.041590</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2111.8</td>\n",
       "      <td>204.068028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "38                -0.921704                0.018684             0.636542   \n",
       "27                -0.971748                0.006853             0.602374   \n",
       "25                -0.962020                0.006822             0.608626   \n",
       "26                -0.972980                0.009915             0.601084   \n",
       "22                -0.963975                0.009365             0.605918   \n",
       "29                -0.967210                0.008703             0.604667   \n",
       "23                -0.969241                0.012705             0.603251   \n",
       "41                -0.929359                0.016049             0.633125   \n",
       "45                -0.936107                0.010399             0.628708   \n",
       "10                -1.007283                0.004107             0.577750   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "38            0.008594              -1.079046           0.536333   \n",
       "27            0.004507              -1.078532           0.534667   \n",
       "25            0.003416              -1.077733           0.535833   \n",
       "26            0.006213              -1.078416           0.533833   \n",
       "22            0.006336              -1.078497           0.536667   \n",
       "29            0.004277              -1.077951           0.534000   \n",
       "23            0.006571              -1.078704           0.535000   \n",
       "41            0.009576              -1.079837           0.534833   \n",
       "45            0.004414              -1.079403           0.533833   \n",
       "10            0.004104              -1.081280           0.535167   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "38                     0.698564                        0.699907   \n",
       "27                     0.698637                        0.699896   \n",
       "25                     0.698661                        0.699891   \n",
       "26                     0.698628                        0.699880   \n",
       "22                     0.698623                        0.699867   \n",
       "29                     0.698652                        0.699827   \n",
       "23                     0.698608                        0.699809   \n",
       "41                     0.698511                        0.699781   \n",
       "45                     0.698540                        0.699777   \n",
       "10                     0.698291                        0.699765   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  Iterations  \\\n",
       "38                    0.008404                      0.041222        10.0   \n",
       "27                    0.008249                      0.041990        10.0   \n",
       "25                    0.008253                      0.041848        10.0   \n",
       "26                    0.008289                      0.042224        10.0   \n",
       "22                    0.008255                      0.042450        10.0   \n",
       "29                    0.008256                      0.042107        10.0   \n",
       "23                    0.008275                      0.042516        10.0   \n",
       "41                    0.008366                      0.041595        10.0   \n",
       "45                    0.008408                      0.041706        10.0   \n",
       "10                    0.008108                      0.041590        10.0   \n",
       "\n",
       "    depth  learning_rate  l2_norm  best_iterations_mean  best_iterations_std  \n",
       "38    8.0          0.050     20.0                 331.2            54.049607  \n",
       "27    6.0          0.010     30.0                2071.0           269.165377  \n",
       "25    6.0          0.010     10.0                1359.8            98.253550  \n",
       "26    6.0          0.010     20.0                1648.2           209.965140  \n",
       "22    6.0          0.050     20.0                 364.8            35.050820  \n",
       "29    6.0          0.005     10.0                2560.6           280.786467  \n",
       "23    6.0          0.050     30.0                 428.6            61.467390  \n",
       "41    8.0          0.010     10.0                1035.4           164.077543  \n",
       "45    8.0          0.005     10.0                1936.2           224.867428  \n",
       "10    4.0          0.010     20.0                2111.8           204.068028  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Target_Mean_Encoding_9.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 4, lr 0.1, l2 10, rounded 0.64759034000\n",
    "# es 100, depth 6, lr 0.005, l2 5, rounded 0.64856714000\n",
    "# es 100, depth 8, lr 0.005, l2 10, rounded 0.6515151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-0.958921</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.610375</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>-1.074936</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.699020</td>\n",
       "      <td>0.700624</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.040499</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1684.8</td>\n",
       "      <td>319.923991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.949829</td>\n",
       "      <td>0.017651</td>\n",
       "      <td>0.614625</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>-1.074169</td>\n",
       "      <td>0.540667</td>\n",
       "      <td>0.699068</td>\n",
       "      <td>0.700510</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.040817</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1354.2</td>\n",
       "      <td>285.665819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>-0.971666</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.603376</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>-1.075565</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.699028</td>\n",
       "      <td>0.700507</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.040592</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2888.0</td>\n",
       "      <td>111.565228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.954765</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>0.612791</td>\n",
       "      <td>0.005593</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>0.540167</td>\n",
       "      <td>0.699060</td>\n",
       "      <td>0.700499</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.040713</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2547.0</td>\n",
       "      <td>306.292670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>-0.962153</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.608917</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>-1.075215</td>\n",
       "      <td>0.539667</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.700498</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.040767</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2002.2</td>\n",
       "      <td>166.670213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>-0.944656</td>\n",
       "      <td>0.016175</td>\n",
       "      <td>0.616540</td>\n",
       "      <td>0.008437</td>\n",
       "      <td>-1.075181</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>0.698979</td>\n",
       "      <td>0.700398</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.039911</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>390.8</td>\n",
       "      <td>82.782607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>-0.945907</td>\n",
       "      <td>0.017432</td>\n",
       "      <td>0.617252</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>-1.074621</td>\n",
       "      <td>0.539833</td>\n",
       "      <td>0.698995</td>\n",
       "      <td>0.700358</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>478.2</td>\n",
       "      <td>78.313217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>-0.942586</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.618122</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>-1.074573</td>\n",
       "      <td>0.536833</td>\n",
       "      <td>0.699009</td>\n",
       "      <td>0.700355</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.040502</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>290.4</td>\n",
       "      <td>61.052764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>-0.935970</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.622749</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>-1.075929</td>\n",
       "      <td>0.537833</td>\n",
       "      <td>0.698867</td>\n",
       "      <td>0.700352</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.040291</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>154.6</td>\n",
       "      <td>33.601190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-0.944708</td>\n",
       "      <td>0.017038</td>\n",
       "      <td>0.617456</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>-1.075680</td>\n",
       "      <td>0.540667</td>\n",
       "      <td>0.698945</td>\n",
       "      <td>0.700292</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>39.834658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "26                -0.958921                0.014594             0.610375   \n",
       "25                -0.949829                0.017651             0.614625   \n",
       "30                -0.971666                0.004124             0.603376   \n",
       "29                -0.954765                0.007994             0.612791   \n",
       "27                -0.962153                0.005269             0.608917   \n",
       "22                -0.944656                0.016175             0.616540   \n",
       "23                -0.945907                0.017432             0.617252   \n",
       "21                -0.942586                0.016096             0.618122   \n",
       "17                -0.935970                0.019757             0.622749   \n",
       "18                -0.944708                0.017038             0.617456   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "26            0.006719              -1.074936           0.539000   \n",
       "25            0.009293              -1.074169           0.540667   \n",
       "30            0.003225              -1.075565           0.539000   \n",
       "29            0.005593              -1.074401           0.540167   \n",
       "27            0.002556              -1.075215           0.539667   \n",
       "22            0.008437              -1.075181           0.539500   \n",
       "23            0.009999              -1.074621           0.539833   \n",
       "21            0.010583              -1.074573           0.536833   \n",
       "17            0.011879              -1.075929           0.537833   \n",
       "18            0.008865              -1.075680           0.540667   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "26                     0.699020                        0.700624   \n",
       "25                     0.699068                        0.700510   \n",
       "30                     0.699028                        0.700507   \n",
       "29                     0.699060                        0.700499   \n",
       "27                     0.699035                        0.700498   \n",
       "22                     0.698979                        0.700398   \n",
       "23                     0.698995                        0.700358   \n",
       "21                     0.699009                        0.700355   \n",
       "17                     0.698867                        0.700352   \n",
       "18                     0.698945                        0.700292   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  Iterations  \\\n",
       "26                    0.008291                      0.040499        10.0   \n",
       "25                    0.008276                      0.040817        10.0   \n",
       "30                    0.008319                      0.040592        10.0   \n",
       "29                    0.008279                      0.040713        10.0   \n",
       "27                    0.008294                      0.040767        10.0   \n",
       "22                    0.008248                      0.039911        10.0   \n",
       "23                    0.008268                      0.041128        10.0   \n",
       "21                    0.008248                      0.040502        10.0   \n",
       "17                    0.008213                      0.040291        10.0   \n",
       "18                    0.008113                      0.039472        10.0   \n",
       "\n",
       "    depth  learning_rate  l2_norm  best_iterations_mean  best_iterations_std  \n",
       "26    6.0          0.010     20.0                1684.8           319.923991  \n",
       "25    6.0          0.010     10.0                1354.2           285.665819  \n",
       "30    6.0          0.005     20.0                2888.0           111.565228  \n",
       "29    6.0          0.005     10.0                2547.0           306.292670  \n",
       "27    6.0          0.010     30.0                2002.2           166.670213  \n",
       "22    6.0          0.050     20.0                 390.8            82.782607  \n",
       "23    6.0          0.050     30.0                 478.2            78.313217  \n",
       "21    6.0          0.050     10.0                 290.4            61.052764  \n",
       "17    6.0          0.100     10.0                 154.6            33.601190  \n",
       "18    6.0          0.100     20.0                 196.0            39.834658  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Target_Mean_Encoding_11.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 6, lr 0.005, l2 10, rounded 0.6437126\n",
    "# es 100, depth 6, lr 0.1, l2 20, rounded 0.6379822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.946526</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>0.617834</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>-1.074061</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.699174</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.041386</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2523.6</td>\n",
       "      <td>317.465967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>-0.918256</td>\n",
       "      <td>0.021368</td>\n",
       "      <td>0.634208</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>-1.073703</td>\n",
       "      <td>0.539667</td>\n",
       "      <td>0.699158</td>\n",
       "      <td>0.700605</td>\n",
       "      <td>0.008432</td>\n",
       "      <td>0.039808</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>326.8</td>\n",
       "      <td>62.652693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-0.946179</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.618626</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>-1.074664</td>\n",
       "      <td>0.539333</td>\n",
       "      <td>0.699086</td>\n",
       "      <td>0.700490</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.041248</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1737.8</td>\n",
       "      <td>224.317097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.938998</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>-1.073323</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.699178</td>\n",
       "      <td>0.700460</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1351.4</td>\n",
       "      <td>163.448585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.975322</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.598586</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>-1.074975</td>\n",
       "      <td>0.543167</td>\n",
       "      <td>0.699085</td>\n",
       "      <td>0.700458</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.040455</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2030.8</td>\n",
       "      <td>307.343066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>-0.925837</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>0.628627</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>-1.075679</td>\n",
       "      <td>0.539833</td>\n",
       "      <td>0.699005</td>\n",
       "      <td>0.700374</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.040350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>156.2</td>\n",
       "      <td>40.031987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>-0.934118</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.623709</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>-1.075391</td>\n",
       "      <td>0.540167</td>\n",
       "      <td>0.698969</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>387.6</td>\n",
       "      <td>62.993968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>-0.949457</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>0.615625</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>-1.075683</td>\n",
       "      <td>0.538833</td>\n",
       "      <td>0.699038</td>\n",
       "      <td>0.700321</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.041022</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>418.2</td>\n",
       "      <td>73.901015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>-0.951249</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>0.615959</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>-1.075088</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.699109</td>\n",
       "      <td>0.700307</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>0.040584</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2064.4</td>\n",
       "      <td>284.772611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>-0.986812</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>-1.076030</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.699044</td>\n",
       "      <td>0.700302</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.040577</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2555.6</td>\n",
       "      <td>145.932313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "29                -0.946526                0.012080             0.617834   \n",
       "21                -0.918256                0.021368             0.634208   \n",
       "26                -0.946179                0.013083             0.618626   \n",
       "25                -0.938998                0.012521             0.622459   \n",
       "9                 -0.975322                0.015426             0.598586   \n",
       "17                -0.925837                0.028243             0.628627   \n",
       "22                -0.934118                0.016113             0.623709   \n",
       "23                -0.949457                0.016133             0.615625   \n",
       "27                -0.951249                0.015087             0.615959   \n",
       "11                -0.986812                0.006248             0.591667   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "29            0.006446              -1.074061           0.540000   \n",
       "21            0.009858              -1.073703           0.539667   \n",
       "26            0.008365              -1.074664           0.539333   \n",
       "25            0.007815              -1.073323           0.539000   \n",
       "9             0.008079              -1.074975           0.543167   \n",
       "17            0.015708              -1.075679           0.539833   \n",
       "22            0.009637              -1.075391           0.540167   \n",
       "23            0.009478              -1.075683           0.538833   \n",
       "27            0.007992              -1.075088           0.540000   \n",
       "11            0.004273              -1.076030           0.541667   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "29                     0.699174                        0.700611   \n",
       "21                     0.699158                        0.700605   \n",
       "26                     0.699086                        0.700490   \n",
       "25                     0.699178                        0.700460   \n",
       "9                      0.699085                        0.700458   \n",
       "17                     0.699005                        0.700374   \n",
       "22                     0.698969                        0.700349   \n",
       "23                     0.699038                        0.700321   \n",
       "27                     0.699109                        0.700307   \n",
       "11                     0.699044                        0.700302   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  Iterations  \\\n",
       "29                    0.008403                      0.041386        10.0   \n",
       "21                    0.008432                      0.039808        10.0   \n",
       "26                    0.008404                      0.041248        10.0   \n",
       "25                    0.008379                      0.041199        10.0   \n",
       "9                     0.008221                      0.040455        10.0   \n",
       "17                    0.008418                      0.040350        10.0   \n",
       "22                    0.008409                      0.041107        10.0   \n",
       "23                    0.008430                      0.041022        10.0   \n",
       "27                    0.008405                      0.040584        10.0   \n",
       "11                    0.008215                      0.040577        10.0   \n",
       "\n",
       "    depth  learning_rate  l2_norm  best_iterations_mean  best_iterations_std  \n",
       "29    6.0          0.005     10.0                2523.6           317.465967  \n",
       "21    6.0          0.050     10.0                 326.8            62.652693  \n",
       "26    6.0          0.010     20.0                1737.8           224.317097  \n",
       "25    6.0          0.010     10.0                1351.4           163.448585  \n",
       "9     4.0          0.010     10.0                2030.8           307.343066  \n",
       "17    6.0          0.100     10.0                 156.2            40.031987  \n",
       "22    6.0          0.050     20.0                 387.6            62.993968  \n",
       "23    6.0          0.050     30.0                 418.2            73.901015  \n",
       "27    6.0          0.010     30.0                2064.4           284.772611  \n",
       "11    4.0          0.010     30.0                2555.6           145.932313  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Target_Mean_Encoding_15.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 6, lr 0.05, l2 10, rounded 0.64467764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>-0.955686</td>\n",
       "      <td>0.005582</td>\n",
       "      <td>0.613416</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>-1.078202</td>\n",
       "      <td>0.530833</td>\n",
       "      <td>0.698427</td>\n",
       "      <td>0.699757</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.041716</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>453.6</td>\n",
       "      <td>49.524136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>-0.944430</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.619836</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>-1.078154</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>0.698445</td>\n",
       "      <td>0.699757</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>303.4</td>\n",
       "      <td>30.203311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-0.995418</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.585917</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>-1.078651</td>\n",
       "      <td>0.532167</td>\n",
       "      <td>0.698369</td>\n",
       "      <td>0.699655</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.041760</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2327.8</td>\n",
       "      <td>245.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.961906</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.609124</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>-1.077734</td>\n",
       "      <td>0.532167</td>\n",
       "      <td>0.698476</td>\n",
       "      <td>0.699647</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.040785</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2514.4</td>\n",
       "      <td>335.777665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-0.976626</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>-1.078850</td>\n",
       "      <td>0.530667</td>\n",
       "      <td>0.698425</td>\n",
       "      <td>0.699645</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.041381</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>138.221561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.994607</td>\n",
       "      <td>0.008804</td>\n",
       "      <td>0.586208</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>-1.079143</td>\n",
       "      <td>0.529333</td>\n",
       "      <td>0.698318</td>\n",
       "      <td>0.699628</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>0.041204</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1891.8</td>\n",
       "      <td>294.235552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>-0.999526</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.583500</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>-1.078789</td>\n",
       "      <td>0.532167</td>\n",
       "      <td>0.698351</td>\n",
       "      <td>0.699610</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.041811</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2553.4</td>\n",
       "      <td>347.573647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.987739</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>0.593167</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>-1.077874</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.698447</td>\n",
       "      <td>0.699592</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.040174</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>419.6</td>\n",
       "      <td>65.104839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>-0.946204</td>\n",
       "      <td>0.014107</td>\n",
       "      <td>0.618248</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>-1.078167</td>\n",
       "      <td>0.529333</td>\n",
       "      <td>0.698364</td>\n",
       "      <td>0.699560</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.041781</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>408.2</td>\n",
       "      <td>75.914162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.961147</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.609625</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>-1.077874</td>\n",
       "      <td>0.533167</td>\n",
       "      <td>0.698472</td>\n",
       "      <td>0.699541</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.041284</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1262.6</td>\n",
       "      <td>105.551125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "23                -0.955686                0.005582             0.613416   \n",
       "21                -0.944430                0.014022             0.619836   \n",
       "10                -0.995418                0.003633             0.585917   \n",
       "29                -0.961906                0.008942             0.609124   \n",
       "26                -0.976626                0.005984             0.599000   \n",
       "9                 -0.994607                0.008804             0.586208   \n",
       "11                -0.999526                0.006451             0.583500   \n",
       "5                 -0.987739                0.012156             0.593167   \n",
       "22                -0.946204                0.014107             0.618248   \n",
       "25                -0.961147                0.004872             0.609625   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "23            0.003775              -1.078202           0.530833   \n",
       "21            0.010239              -1.078154           0.531500   \n",
       "10            0.002014              -1.078651           0.532167   \n",
       "29            0.006058              -1.077734           0.532167   \n",
       "26            0.003584              -1.078850           0.530667   \n",
       "9             0.004806              -1.079143           0.529333   \n",
       "11            0.002580              -1.078789           0.532167   \n",
       "5             0.006862              -1.077874           0.531000   \n",
       "22            0.007514              -1.078167           0.529333   \n",
       "25            0.004935              -1.077874           0.533167   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "23                     0.698427                        0.699757   \n",
       "21                     0.698445                        0.699757   \n",
       "10                     0.698369                        0.699655   \n",
       "29                     0.698476                        0.699647   \n",
       "26                     0.698425                        0.699645   \n",
       "9                      0.698318                        0.699628   \n",
       "11                     0.698351                        0.699610   \n",
       "5                      0.698447                        0.699592   \n",
       "22                     0.698364                        0.699560   \n",
       "25                     0.698472                        0.699541   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  Iterations  \\\n",
       "23                    0.008216                      0.041716        10.0   \n",
       "21                    0.008264                      0.041554        10.0   \n",
       "10                    0.008122                      0.041760        10.0   \n",
       "29                    0.008236                      0.040785        10.0   \n",
       "26                    0.008243                      0.041381        10.0   \n",
       "9                     0.008091                      0.041204        10.0   \n",
       "11                    0.008129                      0.041811        10.0   \n",
       "5                     0.008011                      0.040174        10.0   \n",
       "22                    0.008190                      0.041781        10.0   \n",
       "25                    0.008210                      0.041284        10.0   \n",
       "\n",
       "    depth  learning_rate  l2_norm  best_iterations_mean  best_iterations_std  \n",
       "23    6.0          0.050     30.0                 453.6            49.524136  \n",
       "21    6.0          0.050     10.0                 303.4            30.203311  \n",
       "10    4.0          0.010     20.0                2327.8           245.923077  \n",
       "29    6.0          0.005     10.0                2514.4           335.777665  \n",
       "26    6.0          0.010     20.0                1442.0           138.221561  \n",
       "9     4.0          0.010     10.0                1891.8           294.235552  \n",
       "11    4.0          0.010     30.0                2553.4           347.573647  \n",
       "5     4.0          0.050     10.0                 419.6            65.104839  \n",
       "22    6.0          0.050     20.0                 408.2            75.914162  \n",
       "25    6.0          0.010     10.0                1262.6           105.551125  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Weight_of_Evidence_10.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 6, lr 0.1, l2 20, rounded 0.6427504\n",
    "# es 100, depth 4, lr 0.1, l2 20, rounded 0.6456456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.952681</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.614707</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>-1.072259</td>\n",
       "      <td>0.542167</td>\n",
       "      <td>0.699075</td>\n",
       "      <td>0.700421</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.037375</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2417.6</td>\n",
       "      <td>188.380041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>-0.950664</td>\n",
       "      <td>0.019712</td>\n",
       "      <td>0.611248</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>-1.073001</td>\n",
       "      <td>0.536333</td>\n",
       "      <td>0.699044</td>\n",
       "      <td>0.700350</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.036784</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>126.2</td>\n",
       "      <td>30.360501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>-0.935144</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.622790</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>-1.072849</td>\n",
       "      <td>0.537833</td>\n",
       "      <td>0.698984</td>\n",
       "      <td>0.700335</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.036090</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30.0</td>\n",
       "      <td>247.4</td>\n",
       "      <td>27.295421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.984149</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>0.593082</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>-1.071473</td>\n",
       "      <td>0.538667</td>\n",
       "      <td>0.699202</td>\n",
       "      <td>0.700308</td>\n",
       "      <td>0.008153</td>\n",
       "      <td>0.036209</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>467.2</td>\n",
       "      <td>98.165982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>-0.945247</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.617624</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>-1.072790</td>\n",
       "      <td>0.540333</td>\n",
       "      <td>0.698978</td>\n",
       "      <td>0.700286</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.036903</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>360.2</td>\n",
       "      <td>40.479130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.977074</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.596833</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>-1.071101</td>\n",
       "      <td>0.539333</td>\n",
       "      <td>0.699148</td>\n",
       "      <td>0.700280</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.036235</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>407.4</td>\n",
       "      <td>51.894508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-0.954394</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.611874</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>-1.072180</td>\n",
       "      <td>0.539667</td>\n",
       "      <td>0.699071</td>\n",
       "      <td>0.700258</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.037168</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1627.2</td>\n",
       "      <td>200.146346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-0.958869</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.608500</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>-1.074480</td>\n",
       "      <td>0.536167</td>\n",
       "      <td>0.698987</td>\n",
       "      <td>0.700226</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.037393</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>157.4</td>\n",
       "      <td>13.230268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>-0.961860</td>\n",
       "      <td>0.009107</td>\n",
       "      <td>0.608832</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>-1.072927</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>0.699026</td>\n",
       "      <td>0.700174</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.037236</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>245.902420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.946782</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>0.617207</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>-1.072139</td>\n",
       "      <td>0.540167</td>\n",
       "      <td>0.699043</td>\n",
       "      <td>0.700158</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.037582</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1292.2</td>\n",
       "      <td>254.553256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "29                -0.952681                0.002247             0.614707   \n",
       "17                -0.950664                0.019712             0.611248   \n",
       "19                -0.935144                0.008575             0.622790   \n",
       "6                 -0.984149                0.013752             0.593082   \n",
       "22                -0.945247                0.010261             0.617624   \n",
       "5                 -0.977074                0.010267             0.596833   \n",
       "26                -0.954394                0.007874             0.611874   \n",
       "18                -0.958869                0.006397             0.608500   \n",
       "27                -0.961860                0.009107             0.608832   \n",
       "25                -0.946782                0.015578             0.617207   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "29            0.003348              -1.072259           0.542167   \n",
       "17            0.012720              -1.073001           0.536333   \n",
       "19            0.005282              -1.072849           0.537833   \n",
       "6             0.006150              -1.071473           0.538667   \n",
       "22            0.005944              -1.072790           0.540333   \n",
       "5             0.005573              -1.071101           0.539333   \n",
       "26            0.005577              -1.072180           0.539667   \n",
       "18            0.003442              -1.074480           0.536167   \n",
       "27            0.004516              -1.072927           0.539500   \n",
       "25            0.010478              -1.072139           0.540167   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "29                     0.699075                        0.700421   \n",
       "17                     0.699044                        0.700350   \n",
       "19                     0.698984                        0.700335   \n",
       "6                      0.699202                        0.700308   \n",
       "22                     0.698978                        0.700286   \n",
       "5                      0.699148                        0.700280   \n",
       "26                     0.699071                        0.700258   \n",
       "18                     0.698987                        0.700226   \n",
       "27                     0.699026                        0.700174   \n",
       "25                     0.699043                        0.700158   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  Iterations  \\\n",
       "29                    0.008308                      0.037375        10.0   \n",
       "17                    0.008257                      0.036784        10.0   \n",
       "19                    0.008291                      0.036090        10.0   \n",
       "6                     0.008153                      0.036209        10.0   \n",
       "22                    0.008294                      0.036903        10.0   \n",
       "5                     0.008185                      0.036235        10.0   \n",
       "26                    0.008314                      0.037168        10.0   \n",
       "18                    0.008352                      0.037393        10.0   \n",
       "27                    0.008325                      0.037236        10.0   \n",
       "25                    0.008317                      0.037582        10.0   \n",
       "\n",
       "    depth  learning_rate  l2_norm  best_iterations_mean  best_iterations_std  \n",
       "29    6.0          0.005     10.0                2417.6           188.380041  \n",
       "17    6.0          0.100     10.0                 126.2            30.360501  \n",
       "19    6.0          0.100     30.0                 247.4            27.295421  \n",
       "6     4.0          0.050     20.0                 467.2            98.165982  \n",
       "22    6.0          0.050     20.0                 360.2            40.479130  \n",
       "5     4.0          0.050     10.0                 407.4            51.894508  \n",
       "26    6.0          0.010     20.0                1627.2           200.146346  \n",
       "18    6.0          0.100     20.0                 157.4            13.230268  \n",
       "27    6.0          0.010     30.0                1854.0           245.902420  \n",
       "25    6.0          0.010     10.0                1292.2           254.553256  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Weight_of_Evidence_13.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 6, lr 0.1, l2 10, rounded 0.6456456\n",
    "# es 100, depth 4, lr 0.1, l2 10, rounded 0.64467764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_neg_log_loss_mean</th>\n",
       "      <th>train_neg_log_loss_std</th>\n",
       "      <th>train_accuracy_mean</th>\n",
       "      <th>train_accuracy_std</th>\n",
       "      <th>validate_neg_log_loss</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>validate_offline_score_mean</th>\n",
       "      <th>validate_offline_score_rounded</th>\n",
       "      <th>validate_offline_score_std</th>\n",
       "      <th>validate_offline_score_range</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_norm</th>\n",
       "      <th>best_iterations_mean</th>\n",
       "      <th>best_iterations_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-0.932781</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.624041</td>\n",
       "      <td>0.008318</td>\n",
       "      <td>-1.069165</td>\n",
       "      <td>0.540167</td>\n",
       "      <td>0.699552</td>\n",
       "      <td>0.700835</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>274.883976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.962121</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.603543</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>-1.067698</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.699685</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.037025</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>551.6</td>\n",
       "      <td>113.418870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-0.967276</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.600625</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>-1.068170</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.699729</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>609.2</td>\n",
       "      <td>137.378892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.931757</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>0.625416</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>-1.068375</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.699621</td>\n",
       "      <td>0.700776</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>0.038518</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2710.2</td>\n",
       "      <td>243.198191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>-0.940523</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.620167</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>-1.069608</td>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.699486</td>\n",
       "      <td>0.700754</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2119.4</td>\n",
       "      <td>223.029684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.955483</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.607291</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>-1.068413</td>\n",
       "      <td>0.539333</td>\n",
       "      <td>0.699599</td>\n",
       "      <td>0.700725</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.038794</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30.0</td>\n",
       "      <td>352.4</td>\n",
       "      <td>33.127632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.957732</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.606875</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>-1.067355</td>\n",
       "      <td>0.539667</td>\n",
       "      <td>0.699683</td>\n",
       "      <td>0.700715</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.037695</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>61.546730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.926191</td>\n",
       "      <td>0.019090</td>\n",
       "      <td>0.629622</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>-1.068597</td>\n",
       "      <td>0.539833</td>\n",
       "      <td>0.699549</td>\n",
       "      <td>0.700711</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.038424</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>267.507757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-0.916891</td>\n",
       "      <td>0.025448</td>\n",
       "      <td>0.631878</td>\n",
       "      <td>0.013199</td>\n",
       "      <td>-1.070164</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.699460</td>\n",
       "      <td>0.700710</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>0.038413</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>217.4</td>\n",
       "      <td>51.059181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.964295</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.603376</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>-1.068335</td>\n",
       "      <td>0.540333</td>\n",
       "      <td>0.699612</td>\n",
       "      <td>0.700684</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.038089</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2122.6</td>\n",
       "      <td>159.953243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_neg_log_loss_mean  train_neg_log_loss_std  train_accuracy_mean  \\\n",
       "26                -0.932781                0.014354             0.624041   \n",
       "6                 -0.962121                0.017341             0.603543   \n",
       "7                 -0.967276                0.018754             0.600625   \n",
       "29                -0.931757                0.008683             0.625416   \n",
       "27                -0.940523                0.011248             0.620167   \n",
       "3                 -0.955483                0.007563             0.607291   \n",
       "5                 -0.957732                0.013001             0.606875   \n",
       "25                -0.926191                0.019090             0.629622   \n",
       "18                -0.916891                0.025448             0.631878   \n",
       "9                 -0.964295                0.008378             0.603376   \n",
       "\n",
       "    train_accuracy_std  validate_neg_log_loss  validate_accuracy  \\\n",
       "26            0.008318              -1.069165           0.540167   \n",
       "6             0.006223              -1.067698           0.540000   \n",
       "7             0.006444              -1.068170           0.536667   \n",
       "29            0.004187              -1.068375           0.541000   \n",
       "27            0.004397              -1.069608           0.538333   \n",
       "3             0.004610              -1.068413           0.539333   \n",
       "5             0.006205              -1.067355           0.539667   \n",
       "25            0.010455              -1.068597           0.539833   \n",
       "18            0.013199              -1.070164           0.542667   \n",
       "9             0.003734              -1.068335           0.540333   \n",
       "\n",
       "    validate_offline_score_mean  validate_offline_score_rounded  \\\n",
       "26                     0.699552                        0.700835   \n",
       "6                      0.699685                        0.700787   \n",
       "7                      0.699729                        0.700787   \n",
       "29                     0.699621                        0.700776   \n",
       "27                     0.699486                        0.700754   \n",
       "3                      0.699599                        0.700725   \n",
       "5                      0.699683                        0.700715   \n",
       "25                     0.699549                        0.700711   \n",
       "18                     0.699460                        0.700710   \n",
       "9                      0.699612                        0.700684   \n",
       "\n",
       "    validate_offline_score_std  validate_offline_score_range  Iterations  \\\n",
       "26                    0.008517                      0.038674        10.0   \n",
       "6                     0.008352                      0.037025        10.0   \n",
       "7                     0.008332                      0.037323        10.0   \n",
       "29                    0.008490                      0.038518        10.0   \n",
       "27                    0.008489                      0.038674        10.0   \n",
       "3                     0.008393                      0.038794        10.0   \n",
       "5                     0.008350                      0.037695        10.0   \n",
       "25                    0.008467                      0.038424        10.0   \n",
       "18                    0.008466                      0.038413        10.0   \n",
       "9                     0.008344                      0.038089        10.0   \n",
       "\n",
       "    depth  learning_rate  l2_norm  best_iterations_mean  best_iterations_std  \n",
       "26    6.0          0.010     20.0                1847.0           274.883976  \n",
       "6     4.0          0.050     20.0                 551.6           113.418870  \n",
       "7     4.0          0.050     30.0                 609.2           137.378892  \n",
       "29    6.0          0.005     10.0                2710.2           243.198191  \n",
       "27    6.0          0.010     30.0                2119.4           223.029684  \n",
       "3     4.0          0.100     30.0                 352.4            33.127632  \n",
       "5     4.0          0.050     10.0                 462.0            61.546730  \n",
       "25    6.0          0.010     10.0                1433.0           267.507757  \n",
       "18    6.0          0.100     20.0                 217.4            51.059181  \n",
       "9     4.0          0.010     10.0                2122.6           159.953243  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Weight_of_Evidence_17.pkl')\n",
    "check(data, 'validate_offline_score_rounded', N)\n",
    "# es 100, depth 4, lr 0.1, l2 10, rounded 0.63893014\n",
    "# es 100, depth 6, lr 0.1, l2 10, rounded 0.6379822\n",
    "# es 100, depth 6, lr 0.01, l2 20, rounded0.63893014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
